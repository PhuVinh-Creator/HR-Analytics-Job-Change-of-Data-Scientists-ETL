# -*- coding: utf-8 -*-
"""Vinh_HR Analytics: Job Change of Data Scientists (ETL)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13T8QBCm7c37_3KlmS8kOxQAT1ANp-P7d

# **ğŸ•µï¸â€â™‚ï¸ HR Analytics: Job Change of Data Scientists (ETL)**

# **1. Import Libraries ğŸ“š**
"""

import pandas as pd

!pip install pymysql

from sqlalchemy import create_engine
import pymysql

"""# **2. Extract Data ğŸ—ƒï¸**

## 2.1 Enrollies' data ğŸ—‚ï¸

As enrollies are submitting their request to join the course via Google Forms, we have the Google Sheet that stores data about enrolled students, containing the following columns:

- enrollee_id: unique ID of an enrollee
- full_name: full name of an enrollee
- city: the name of an enrollie's city
- gender: gender of an enrollee

The source: https://docs.google.com/spreadsheets/d/1VCkHwBjJGRJ21asd9pxW4_0z2PWuKhbLR3gUHm-p4GI/edit?usp=sharing
"""

google_sheet_id = '1VCkHwBjJGRJ21asd9pxW4_0z2PWuKhbLR3gUHm-p4GI'
url = 'https://docs.google.com/spreadsheets/d/' + google_sheet_id + '/export?format=xlsx'
enrollies_data = pd.read_excel(url, sheet_name = 'enrollies')

enrollies_data.head()

"""## 2.2 Enrollies' education ğŸ«

After enrollment everyone should fill the form about their education level. This form is being digitalized manually. Educational department stores it in the Excel format here: https://assets.swisscoding.edu.vn/company_course/enrollies_education.xlsx

This table contains the following columns:

- enrollee_id: A unique identifier for each enrollee. This integer value uniquely distinguishes each participant in the dataset.

- enrolled_university: Indicates the enrollee's university enrollment status. Possible values include no_enrollment, Part time course, and Full time course.

- education_level: Represents the highest level of education attained by the enrollee. Examples include Graduate, Masters, etc.

- major_discipline: Specifies the primary field of study for the enrollee. Examples include STEM, Business Degree, etc.
"""

excel_url = 'https://assets.swisscoding.edu.vn/company_course/enrollies_education.xlsx' 
excel_response = requests.get(excel_url)
with open('enrollies_education.xlsx', 'wb') as file:
    file.write(excel_response.content)
enrollies_education = pd.read_excel ('enrollies_education.xlsx')
enrollies_education.head()

"""## 2.3 Enrollies' working experience ğŸª´

Another survey that is being collected manually by educational department is about working experience.

Educational department stores it in the CSV format here: https://assets.swisscoding.edu.vn/company_course/work_experience.csv

This table contains the following columns:

- enrollee_id: A unique identifier for each enrollee. This integer value uniquely distinguishes each participant in the dataset.

- relevent_experience: Indicates whether the enrollee has relevant work experience related to the field they are currently studying or working in. Possible values include Has relevent experience and No relevent experience.

- experience: Represents the number of years of work experience the enrollee has. This can be a specific number or a range (e.g., >20, <1).

- company_size: Specifies the size of the company where the enrollee has worked, based on the number of employees. Examples include 50âˆ’99, 100âˆ’500, etc.

- company_type: Indicates the type of company where the enrollee has worked. Examples include Pvt Ltd, Funded Startup, etc.

- last_new_job: Represents the number of years since the enrollee's last job change. Examples include never, >4, 1, etc.
"""

work_experience_url = 'https://assets.swisscoding.edu.vn/company_course/work_experience.csv'
csv_response = requests.get(work_experience_url)
with open('work_experience.csv', 'wb') as file:
    file.write(csv_response.content)
work_experience = pd.read_csv('work_experience.csv')
work_experience.head()

"""## 2.4 Training hours âŒ›

From LMS system's database you can retrieve a number of training hours for each student that they have completed.

**Database credentials:**

- Database type: MySQL
- Host: 112.213.86.31
- Port: 3360
- Login: etl_practice
- Password: 550814
- Database name: company_course
- Table name: training_hours
"""

engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')
training_hours = pd.read_sql_table('training_hours', engine)

training_hours.head()

"""## 2.5 City development index ğŸ™ï¸

Another source that can be usefull is the table of City development index.

The City Development Index (CDI) is a measure designed to capture the level of development in cities. It may be significant for the resulting prediction of student's employment motivation.

It is stored here: https://sca-programming-school.github.io/city_development_index/index.html
"""

tables = pd.read_html('https://sca-programming-school.github.io/city_development_index/index.html')

cities = tables[0]

cities.head()

"""## 2.6 Employment ğŸ‘©â€ğŸ’»

From LMS database you can also retrieve the fact of employment. If student is marked as employed, it means that this student started to work in our company after finishing the course.

**Database credentials:**

- Database type: MySQL
- Host: 112.213.86.31
- Port: 3360
- Login: etl_practice
- Password: 550814
- Database name: company_course
- Table name: employment
"""

engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')
employment = pd.read_sql_table('employment', engine)

employment.head()

"""# **3. Transform data ğŸ› ï¸**

## 3.1 Enrollies' data ğŸ—‚ï¸

### Check code type and data quality
"""

enrollies_data.info()

enrollies_data['gender'].unique()

"""### Fix data type"""

enrollies_data['full_name'] = enrollies_data['full_name'].astype('string')

enrollies_data['city'] = enrollies_data['city'].astype('category')
enrollies_data['gender'] = enrollies_data['gender'].astype('category')

"""### Fill missing values"""

gender_mode = enrollies_data['gender'].mode()[0]
enrollies_data['gender'] = enrollies_data['gender'].fillna(gender_mode)

enrollies_data.info()

"""## 3.2 Enrollies' education ğŸ«

### Check code type and data quality
"""

enrollies_education.info()

for col in enrollies_education.columns:
  if col != 'enrollee_id':
    print(f"ğŸ—‚ï¸ Unique values in '{col}': {enrollies_education[col].unique()}")
    print()

"""### Fix data type"""

for col in enrollies_education.columns:
  if col != 'enrollee_id':
    enrollies_education[col] = enrollies_education[col].astype('category')

"""### Fill missing values"""

for col in enrollies_education.columns:
  if col != 'enrollee_id':
    enrollies_education_mode = enrollies_education[col].mode()[0]
    enrollies_education[col] = enrollies_education[col].fillna(enrollies_education_mode)
    print(f"ğŸ“¥ Fill missing entries in '{col}' with mode: {enrollies_education_mode}")
    print()

enrollies_education.info()

"""## 3.3 Enrollies' working experience ğŸª´

### Check code type and data quality
"""

work_experience.info()

for col in work_experience.columns:
  if col != 'enrollee_id':
    print(f"ğŸ—‚ï¸ Unique values in '{col}': {work_experience[col].unique()}")
    print()

"""### Fix data type"""

for col in work_experience.columns:
  if col != 'enrollee_id':
    work_experience[col] = work_experience[col].astype('category')

"""### Fill missing values"""

for col in work_experience.columns:
  if work_experience[col].isna().any():
    work_experience_mode = work_experience[col].mode()[0]
    work_experience[col] = work_experience[col].fillna(work_experience_mode)
    print(f"ğŸ“¥ Fill missing entries in '{col}' with mode: {work_experience_mode}")
    print()

work_experience.info()

"""## 3.4 Training hours âŒ›

### Check code type and data quality
"""

training_hours.info()

training_hours['training_hours'].describe()

"""### Handling outliers"""

# Calculate IQR
Q1 = training_hours['training_hours'].quantile(0.25)
Q3 = training_hours['training_hours'].quantile(0.75)
IQR = Q3 - Q1

# Calculate lower and upper bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Remove all outliers
training_hours = training_hours[(training_hours['training_hours'] >= lower_bound) & (training_hours['training_hours'] <= upper_bound)]

training_hours['training_hours'].describe()

"""## 3.5 City development index ğŸ™ï¸

### Check code type and data quality
"""

cities.info()

cities['City Development Index'].describe()

"""### Fix data type"""

cities['City'] = cities['City'].astype('category')

cities.info()

"""## 3.6 Employment ğŸ‘©â€ğŸ’»"""

employment.info()

employment['employed'].unique()

"""âœ… The Employment dataset is clean and has no null value to handle.

# **4. Load data to SQL ğŸ–¥ï¸**
"""

# Define database path and engine
db_path = 'data_warehouse.db'
engine = create_engine(f'sqlite:///{db_path}')

# List of (DataFrame, table_name)
tables = [
    (enrollies_data, 'dim_enrollies_data'),
    (enrollies_education, 'fact_enrollies_education'),
    (work_experience, 'dim_work_experience'),
    (training_hours, 'dim_training_hours'),
    (cities, 'dim_cities'),
    (employment, 'dim_employment')
]

# Create a list to contain all the records
csv_combined = []


# Write each to SQL, Excel and SQL
with pd.ExcelWriter('data_warehouse.xlsx') as writer:
  for df, table_name in tables:
      # Write to SQL
      df.to_sql(table_name, engine, if_exists='replace', index=False)
      # Write to excel
      df.to_excel(writer, sheet_name=table_name, index=False)
      # Write to CSV
      df_with_name = df.copy()
      df_with_name.insert(0, 'table_name', table_name)
      csv_combined.append(df_with_name)

# Combine all data and save to one CSV
combined_df = pd.concat(csv_combined, ignore_index=True)
combined_df.to_csv('data_warehouse.csv', index=False)

print('Data has been saved to all sources âœ…')